{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twilio.rest import Client\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import plotly.express as px\n",
    "import psutil # CPU info\n",
    "import plotly.express as px\n",
    "import multiprocessing as mp\n",
    "import plotly.graph_objects as go\n",
    "import time \n",
    "import glob\n",
    "import shutil, os\n",
    "import json\n",
    "from re import search\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "from twilio.rest import Client\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from distutils.dir_util import copy_tree\n",
    "import plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to df seperating date and time 1900-01-01 TimeStamp = 11:39:09.625\n",
    "def split_date_time(hr):\n",
    "    ts_only = []\n",
    "    for i in hr[\"Time\"]:\n",
    "        ts_only.append(i[11:])\n",
    "    hr[\"TimeStamp\"] = ts_only\n",
    "    \n",
    "# Add a column to the dataframe containing 12 hour timestamp.\n",
    "def convert_ts_human(hr):\n",
    "    # Convert all timetamps to 12 hour format\n",
    "    conveted_human_list = []\n",
    "    for i in hr[\"Time\"]:\n",
    "        d = datetime.strptime(i.split(\" \")[1], \"%H:%M:%S.%f\")\n",
    "        conveted_human_list.append(d.strftime(\"%I:%M:%S %p\")) #12 HR FORMAT.\n",
    "# To filter by Hour and Date&Time. Give it a dataset for one day only apply that filter before feeding.\n",
    "\n",
    "def unique_time_stamps(df):\n",
    "    time_stamp_list = [] # get the unique time stamps int he paricular df.\n",
    "    for idx,val in enumerate(df[\"Time\"]):\n",
    "        #print(\"TS: \",val,val[11:13])\n",
    "        time_stamp_list.append(val[11:13])\n",
    "    return np.unique(np.array(time_stamp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_27 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "p_34 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "p_52 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "p_53 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "p_75 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "p_80 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "p_88 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "p_90 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "p_106 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "p_118 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "p_129 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "p_131 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "# Returns a list of Dates based on Date ID.\n",
    "def get_dates(patient_id):\n",
    "    date_id_list = []\n",
    "    if patient_id == 27:\n",
    "        date_id_list = p_27\n",
    "    elif patient_id == 34:\n",
    "        date_id_list = p_34\n",
    "    elif patient_id == 52:\n",
    "        date_id_list = p_52\n",
    "    elif patient_id == 53:\n",
    "        date_id_list = p_53\n",
    "    elif patient_id == 75:\n",
    "        date_id_list = p_75\n",
    "    elif patient_id == 80:\n",
    "        date_id_list = p_80\n",
    "    elif patient_id == 88:\n",
    "        date_id_list = p_88\n",
    "    elif patient_id == 90:\n",
    "        date_id_list = p_90\n",
    "    elif patient_id == 106:\n",
    "        date_id_list = p_106\n",
    "    elif patient_id == 118:\n",
    "        date_id_list = p_118\n",
    "    elif patient_id == 129:\n",
    "        date_id_list = p_129\n",
    "    elif patient_id == 131:\n",
    "        date_id_list = p_131\n",
    "    return date_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of time in secods per activity bucket.\n",
    "def calculate_time_seconds_each_act(hr):\n",
    "    total_time_each_bucket_seconds = []\n",
    "    unique_ts_each_bucket = []\n",
    "    print(\"Number of buckets \",hr[\"HR_ACT_ZONE_MORE\"].unique())\n",
    "    bucket_info_list = hr[\"HR_ACT_ZONE_MORE\"].unique()\n",
    "    for bucket in [0,1,2,-1]:\n",
    "        print(\"For BUCKET\",bucket)\n",
    "        # Both should have same number of elements.\n",
    "        start_ts_hr_list = []\n",
    "        end_ts_hr_list = []\n",
    "        time_seconds_list = []\n",
    "        #print(\"Bucket\",bucket,\"Data shape\", hr[hr[\"HR_ACT_ZONE_MORE\"]==bucket].shape[0])\n",
    "        #print(\"Data = \", hr[hr[\"HR_ACT_ZONE_MORE\"]==bucket])\n",
    "        unique_ts_beyond_act = unique_time_stamps(hr[hr[\"HR_ACT_ZONE_MORE\"]==bucket])\n",
    "        unique_ts_each_bucket.append(unique_ts_beyond_act)\n",
    "        print(\"UNIQUE TS LIST  = \",len(unique_ts_beyond_act))\n",
    "        for ts_hour in unique_ts_beyond_act:\n",
    "            # In order to calculate time we bucket the timestamp by hour and then for each hour find start and end times and take the diff between those and them sum everything.\n",
    "            val_bool = []\n",
    "            val = []\n",
    "            for i in hr[hr[\"HR_ACT_ZONE_MORE\"]==bucket][\"TimeStamp\"]:\n",
    "                # Bool Ture if condition is met.\n",
    "                val_bool.append(i.startswith(ts_hour))\n",
    "                val.append(i) # Also create a list of actual values.\n",
    "            # Convert to pandas aeries in order to use where.\n",
    "            val_series = pd.Series(val_bool)\n",
    "            start_index = val_series.where(val_series==True).first_valid_index()\n",
    "            end_index = val_series.where(val_series==True).last_valid_index()\n",
    "            start_ts = datetime.strptime(val[start_index], \"%H:%M:%S.%f\") \n",
    "            end_ts = datetime.strptime(val[end_index], \"%H:%M:%S.%f\")\n",
    "            time_seconds = (end_ts - start_ts).total_seconds()\n",
    "            start_ts_hr_list.append(start_ts)\n",
    "            end_ts_hr_list.append(end_ts)\n",
    "            #print(\"Each time in seconds\",time_seconds)\n",
    "            time_seconds_list.append(time_seconds/60) # Length of this list will vary based on ts hour info avaliable.\n",
    "        print(\"time_seconds_list Time in SECONDS list = \",time_seconds_list,\"Length: \",len(time_seconds_list))\n",
    "        #time_seconds_list\n",
    "        total_time = sum(time_seconds_list)\n",
    "        print(\"Total Time = \",total_time)\n",
    "        total_time_each_bucket_seconds.append(total_time)\n",
    "    # Converted text for plot annotations.\n",
    "    str_text_time_mins = []\n",
    "    for i in total_time_each_bucket_seconds:\n",
    "        str_text_time_mins.append(str(int(i)) + \" Minutes\")\n",
    "    return total_time_each_bucket_seconds,str_text_time_mins,bucket_info_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Activity Level Stats: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#patient_id = 88\n",
    "patient_id_list = [27,34,52,53,75,80,88,90,106,118,129,131,584]\n",
    "for patient_id in patient_id_list:\n",
    "    print(\"--------Patient ID -------- :\", patient_id)\n",
    "    start_time = time.time()\n",
    "    date_id_list = get_dates(patient_id)\n",
    "    #print(\"date_id_list = \", date_id_list)\n",
    "    day_wise_mins = []\n",
    "    day_wise_mins_annotation_fotmat = []\n",
    "    bucket_info_day_list = []\n",
    "    # For all Dates of a particlar Patient.\n",
    "    for i in date_id_list:\n",
    "        print(\"--------Date-------- :\", i)\n",
    "        path = \"/Users/shehjarsadhu/Desktop/UniversityOfRhodeIsland/Graduate/ResearchWBL/My_Thesis/careportal-flaskapp/care-portal-thesis-sub/PatientID_\" +str(patient_id) + \"/HR_ACT_Resample_40Hz_PID_\" + str(patient_id) + \"_\" + str(i) + \"_Date_ID_HR.csv\"\n",
    "        hr = pd.read_csv(path)\n",
    "        split_date_time(hr)\n",
    "        total_time_each_bucket_mins,str_text_time_mins,bucket_info_list = calculate_time_seconds_each_act(hr)\n",
    "        day_wise_mins.append(total_time_each_bucket_mins)\n",
    "        day_wise_mins_annotation_fotmat.append(str_text_time_mins)\n",
    "        bucket_info_day_list.append(bucket_info_list)\n",
    "    stop_time = time.time()\n",
    "    day_pandas = pd.DataFrame(day_wise_mins,columns=[\"LessIntense\",\"ModerateIntensity\",\"HighIntensity\",\"BeyondActivity\"])\n",
    "    day_pandas[\"Dates\"] = date_id_list\n",
    "    annotation_df = pd.DataFrame(day_wise_mins_annotation_fotmat,columns=[\"LessIntense\",\"ModerateIntensity\",\"HighIntensity\",\"BeyondActivity\"])\n",
    "    json_Act_levels = {}\n",
    "    for i in day_pandas[\"Dates\"]:\n",
    "        json_Act_levels[i] = day_pandas.iloc[i].to_list()\n",
    "    r = \"/Users/shehjarsadhu/Desktop/UniversityOfRhodeIsland/Graduate/ResearchWBL/My_Thesis/careportal-webapp/static/plotlycharts/\"\n",
    "#     with open(r+\"PatientID_\"+ str(patient_id)+\"timming_\"+str(patient_id)+\"activity_levels.json\", 'w') as outfile:\n",
    "#         json.dump(json_Act_levels, outfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id =88\n",
    "r = \"/Users/shehjarsadhu/Desktop/UniversityOfRhodeIsland/Graduate/ResearchWBL/My_Thesis/careportal-webapp/static/plotlycharts/\"\n",
    "with open(r+\"PatientID_\"+ str(patient_id)+\"/plotly_hr_zone_\"+str(patient_id)+\"activity_levels.json\", 'w') as outfile:\n",
    "    json.dump(json_Act_levels, outfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/shehjarsadhu/Desktop/UniversityOfRhodeIsland/Graduate/ResearchWBL/My_Thesis/careportal-webapp/static/plotlycharts/PatientID_88/PatientID_88timming_88activity_levels.json\"\n",
    "# act_levels = json.load(path)\n",
    "# read file\n",
    "with open(path, 'r') as myfile:\n",
    "    act_levels=myfile.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_levels_json = json.loads(act_levels)\n",
    "dates = get_dates(patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_intense = []\n",
    "moderate_intense = []\n",
    "high_intensity = [] \n",
    "beyond_activity = []\n",
    "sum_list = []\n",
    "for i in act_levels_json.keys():\n",
    "    #print(act_levels_json[i][0])\n",
    "    less_intense.append(act_levels_json[i][0])\n",
    "    moderate_intense.append(act_levels_json[i][1])\n",
    "    high_intensity.append(act_levels_json[i][2])\n",
    "    beyond_activity.append(act_levels_json[i][3])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_day_list = []\n",
    "totals_no_act_list = []\n",
    "for less_intense1, moderate_intense1,high_intensity1,beyond_activity1 in zip(less_intense, moderate_intense,high_intensity,beyond_activity):\n",
    "    s = less_intense1 + moderate_intense1 + high_intensity1 +beyond_activity1\n",
    "    totals_day_list.append(s)\n",
    "    left_over = 1440 - s\n",
    "    print(\"Act\",s,\"Left Over\",left_over,\"Total\",left_over+s)\n",
    "    totals_no_act_list.append(left_over)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = []\n",
    "for i in range(0,len(dd[0])):\n",
    "    widths.append(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths_np = np.array(widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = [less_intense,moderate_intense,high_intensity  , beyond_activity]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAME HEIGHT FOR BAR PLOTS (Viz no data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='No Data', x=dates, y=totals_no_act_list[:7],marker_color='lightslategrey'),\n",
    "    go.Bar(name='No Activity', x=dates, y=less_intense[:7],marker_color = \"teal\"),\n",
    "    go.Bar(name='Moderate Activity', x=dates, y=moderate_intense[:7],text=moderate_intense,marker_color =\"darkseagreen\"),\n",
    "    go.Bar(name='High Activity', x =dates, y=high_intensity[:7],text=high_intensity,marker_color =\"lightseagreen\"),\n",
    "    go.Bar(name='Beyond Activity',x=dates, y=beyond_activity[:7],text=beyond_activity,marker_color =\"red\")])\n",
    "fig.update_xaxes(title=\"Day\")\n",
    "fig.update_yaxes(title=\"Number of Mins\")\n",
    "fig.update_layout(barmode='stack',title =\"Cardiac Activity Levels\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for i in act_levels_json.keys():\n",
    "    dates.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='No Activity', x=dates, y=less_intense),\n",
    "    go.Bar(name='Moderate Activity', x=dates, y=moderate_intense,text=moderate_intense),\n",
    "    go.Bar(name='High Activity', x=dates, y=high_intensity,text=high_intensity),\n",
    "    go.Bar(name='Beyond Activity', x=dates, y=beyond_activity,text=beyond_activity)\n",
    "])\n",
    "\n",
    "fig.update_xaxes(title=\"Day\")\n",
    "fig.update_yaxes(title=\"Activity in Mins\")\n",
    "fig.update_layout(barmode='stack',title =\"Cardiac Activity Levels\")\n",
    "fig.show()\n",
    "# Can improve this chart by makeing the bar stay static.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
